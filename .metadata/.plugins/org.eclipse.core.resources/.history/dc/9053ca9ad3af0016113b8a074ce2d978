package slave_shavadoop;

import java.io.File;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.HashMap;

import master_shavadoop.functions_tool;

//	Class available for all workers, which contains the different functions they need to work.
public class compute_distant {

//	Simulation function for check if the parallelization work correctly 
	public static void simul_compute() throws InterruptedException {
		Thread.sleep(10000);
	}

//	Function for split the Sx files receive from the master to UMx files contains the list of words like [word1 1]
	public static void splits_mapping(String sx_file) {
		HashMap<String, ArrayList<String>> slave_cle_umx = new HashMap<String, ArrayList<String>>();
		ArrayList<String> list_words = new ArrayList<String>();
		ArrayList<String> list_unik_words = new ArrayList<String>();
		
//		 Create the UMx name file from the index of the Sx source 
		String sx_name = Paths.get(sx_file).getFileName().toString();
		String umx_file = "UM" + sx_name.substring(sx_name.length() - 1, sx_name.length());
		new File(umx_file).delete();

//		 Read the Sx file, the function return a ArrayList with each line of the file
		list_words = functions_tool.read_file(sx_file);

//		 Write the UMx file and save the list of unik words contains in the UMx
		for (String list_words_line : list_words) {
			for (String word_no_unik : list_words_line.split(" ")) {
				functions_tool.write_file(umx_file, word_no_unik + " 1");
				 if(!list_unik_words.contains(word_no_unik)){
					 list_unik_words.add(word_no_unik);
				 }
			}
		}
		
//		Create a keys dictionary with the list of words and the UMx name
		slave_cle_umx.put(umx_file, list_unik_words);

//		Format the keys dictionary to send it to the master. We use the standard output for send it to the master
		String str_tmp = "";
		String str_format = "";
		for (String return_tmp : slave_cle_umx.keySet()) {
			ArrayList<String> sl = slave_cle_umx.get(return_tmp);
			for (String return_tmp_sub : sl) {
				str_tmp = str_tmp + return_tmp_sub + " ";
			}
			str_format = return_tmp + " " + str_tmp;
		}
		System.out.println(str_format);
	}
	
	// UMx > RMx
	public static HashMap<String, Integer> shuffling_maps(String params){
		ArrayList<String> list_words_to_reduce = new ArrayList<String>();
		HashMap<String, Integer> words_reduced = new HashMap<String, Integer>();
		ArrayList<String> list_words_all = new ArrayList<String>();
		ArrayList<String> list_words_all_tmp = new ArrayList<String>();
		
		// get parameters
		String word = params.split(" ")[0];
		String smx_cible = params.split(" ")[1].toString();
		String rmx_file = "RM" + smx_cible.substring(smx_cible.length() - 1, smx_cible.length());
		String str_words_reduced_tmp = "";
		
		// get informations of UMx files
		for(String el_param : params.split(" ")){
			if(!el_param.equals(word) && !el_param.equals(smx_cible)){
				list_words_all_tmp.addAll(functions_tool.read_file(el_param));
			}
		}
		
		for(String str_el : list_words_all_tmp){
			if(str_el.split(" ")[0].equals(word)){
				list_words_all.add(str_el);
			}
		}
		
		new File(smx_cible).delete();
		
		// select right word of each file
		for(String word_selected : list_words_all){
			if(word_selected.split(" ")[0].equals(word)){
				functions_tool.write_file(smx_cible, word_selected);
				list_words_to_reduce.add(word_selected.split(" ")[0]);
			}
		}
		//System.out.println(smx_cible);
		//return smx_cible;
		
		new File(rmx_file).delete();

		//list_words_to_reduce = list_words_all;
		
		words_reduced = functions_tool.words_count(list_words_to_reduce);
		
		for(String key_word_reduced :  words_reduced.keySet()){
			str_words_reduced_tmp = key_word_reduced + " " + words_reduced.get(key_word_reduced);
		}
		functions_tool.write_file(rmx_file, str_words_reduced_tmp);
		
		// Key Transfert to the master  
		System.out.println(str_words_reduced_tmp);
		return words_reduced;
	}

	// function merged with shuffling_maps
	public static HashMap<String, Integer> reducing_sorted_maps(String params){
		ArrayList<String> list_words_to_reduce = new ArrayList<String>();
		HashMap<String, Integer> words_reduced = new HashMap<String, Integer>();
		
		String rmx_file = "RM" + params.substring(params.length() - 1, params.length());
		String str_words_reduced_tmp = "";
		
		new File(rmx_file).delete();
		list_words_to_reduce.addAll(functions_tool.read_file(params));
		words_reduced = functions_tool.words_count(list_words_to_reduce);
		for(String key_word_reduced :  words_reduced.keySet()){
			str_words_reduced_tmp = key_word_reduced + " " + words_reduced.get(key_word_reduced);
		}
		functions_tool.write_file(rmx_file, str_words_reduced_tmp);
		System.out.println(str_words_reduced_tmp);
		return words_reduced;
	}
	

	public static void main(String[] args) throws InterruptedException {
		// TODO Auto-generated method stub
		HashMap<String, Integer> cle_rmx_tmp = new HashMap<String, Integer>();
		String cle_smx_tmp;
		
		if (args[0] != null) {
			switch (args[0]) {
			case "simul":
				simul_compute();
				break;
			case "modeSXUMX":
				splits_mapping(args[1]);
				break;
			case "modeUMXSMX":
				int nb_arguments = args.length;
				int i = 1;
				String str_tmp = "";
				while(i < nb_arguments){
					str_tmp = str_tmp + args[i] + " ";
					i++;
				}
				cle_rmx_tmp = shuffling_maps(str_tmp);		// cle_smx_tmp
				//cle_rmx_tmp.putAll(reducing_sorted_maps(cle_smx_tmp));
				break;
			default:
				simul_compute();
				break;
			}
		} else {
			simul_compute();
		}
	}

}
